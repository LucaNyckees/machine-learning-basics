{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can produce a prediction file for the data of the test set for the six different methods that were required.\n",
    "The cross validation of the hyperparameters is not covered in this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from implementations import *\n",
    "from cleaning_data import *\n",
    "from cross_validation import cross_val_LS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the model you will have to do the three essential following tasks: \n",
    "\n",
    "   1) Choose the type of regression: least squares or logistic regression.(To do so put a # in front of the unwanted choice and remove it in front of the wanted choice in the next cell)  \n",
    "   \n",
    "   2) Choose the parameters of the chosen method\n",
    "   \n",
    "   3) Choose the method. (To do so put a # in front of the unwanted choice and remove it in front of the wanted choice in the second next cell)\n",
    "\n",
    "The run.py file and this notebook output with least_squares(y,x) and degree=8 are the same. Be sure to run the cells from the top to the bottom to produce the output file with the name OUTPUT_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choice of regression------------------------------------------------------------------------------------------\n",
    "\n",
    "choice='least squares'\n",
    "#choice='logistic regression'\n",
    "\n",
    "#Choice of parameters------------------------------------------------------------------------------------------\n",
    "\n",
    "degree=1                      #choice of the degree of the polynomial expansion\n",
    "max_iters=50                  #max number of iterations for GD and SGD\n",
    "gamma=0.007                    #step size for GD and SGD\n",
    "lambda_=0.001                  #factor of the regularization for the ridge and logistic regression\n",
    "OUTPUT_PATH='submission.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_0.shape = (99913,)\n",
      "y_1.shape = (77544,)\n",
      "y_23.shape = (72543,)\n",
      "ypred.shape = (250000,)\n",
      "id_ = (250000,)\n",
      "y.shape =  (250000, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75976"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning and adapting the data---------------------------------------------------------------------------------\n",
    "\n",
    "x_0,x_1,x_23=adapt_x(tX,degree)\n",
    "if choice=='least squares':\n",
    "    y_0,y_1,y_23=adapt_y_least_squares(y,tX)\n",
    "elif choice=='logistic regression':\n",
    "    y_0,y_1,y_23=adapt_y_logistic(y,tX)\n",
    "else:\n",
    "    raise SyntaxWarning\n",
    "\n",
    "#Computing the weights and loss on the training set-------------------------------------------------------------\n",
    "\n",
    "#Gradient descent\n",
    "#w_0, loss_w0 = least_squares_SGD(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = least_squares_SGD(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = least_squares_SGD(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Stochastic gradient descent\n",
    "#w_0, loss_w0 = least_squares_SGD(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = least_squares_SGD(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = least_squares_SGD(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Least squares with normal equations\n",
    "w_0, loss_w0 = least_squares(y_0, x_0)\n",
    "w_1, loss_w1 = least_squares(y_1, x_1)\n",
    "w_23, loss_w2 = least_squares(y_23, x_23)\n",
    "\n",
    "#Ridge regression\n",
    "#w_0, loss_w0 = ridge_regression(y_0, x_0, lambda_)\n",
    "#w_1, loss_w1 = ridge_regression(y_1, x_1, lambda_)\n",
    "#w_23, loss_w2 = ridge_regression(y_23, x_23, lambda_)\n",
    "\n",
    "#Logistic regression\n",
    "#w_0, loss_w0 = logistic_regression(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = logistic_regression(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = logistic_regression(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Regularized logistic regression\n",
    "#w_0, loss_w0 = reg_logistic_regression(y_0, x_0, lambda_, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = reg_logistic_regression(y_1, x_1, lambda_, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = reg_logistic_regression(y_23, x_23, lambda_, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Predict on the train set----------------------------------------------------------------------------------------\n",
    "\n",
    "y_pred_tr = label(w_0,w_1,w_23,x_0,x_1,x_23,tX,choice)\n",
    "compute_accuracy(y, y_pred_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning and adapting the data----------------------------------------------------------------------------------\n",
    "x_0_te,x_1_te,x_23_te=adapt_x(tX_test,degree)\n",
    "\n",
    "#Predict on the test set-----------------------------------------------------------------------------------------\n",
    "y_pred_te=label_regression(w_0,w_1,w_23,x_0_te,x_1_te,x_23_te,tX_test,choice)\n",
    "create_csv_submission(ids_test, y_pred_te, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "y_te  (62500,)\n",
      "x_te  (62500, 30)\n",
      "w  (73,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (62500,30) and (73,) not aligned: 30 (dim 1) != 73 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8e41657dfcb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcross_val_LS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/GitHub/ML_Project1/Projet/scripts/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_LS\u001b[0;34m(y, x, k_fold, max_degree)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x_te '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'w '\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mloss_te\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_te\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0mloss_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ML_Project1/Projet/scripts/helper_implementations.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Compute the MSE\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (62500,30) and (73,) not aligned: 30 (dim 1) != 73 (dim 0)"
     ]
    }
   ],
   "source": [
    "cross_val_LS(y,tX,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
