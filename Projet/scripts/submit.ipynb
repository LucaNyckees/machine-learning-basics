{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can produce a prediction file for the data of the test set for the six different methods that were required.\n",
    "The cross validation of the hyperparameters is not covered in this file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "from implementations import *\n",
    "from cleaning_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the model you will have to do the three essential following tasks: \n",
    "\n",
    "   1) Choose the type of regression: least squares or logistic regression.(To do so put a # in front of the unwanted choice and remove it in front of the wanted choice in the next cell)  \n",
    "   \n",
    "   2) Choose the parameters of the chosen method\n",
    "   \n",
    "   3) Choose the method. (To do so put a # in front of the unwanted choice and remove it in front of the wanted choice in the second next cell)\n",
    "\n",
    "The run.py file and this notebook output with least_squares(y,x) and degree=8 are the same. Be sure to run the cells from the top to the bottom to produce the output file with the name OUTPUT_PATH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choice of regression------------------------------------------------------------------------------------------\n",
    "\n",
    "#choice='least squares'\n",
    "choice='logistic regression'\n",
    "\n",
    "#Choice of parameters------------------------------------------------------------------------------------------\n",
    "\n",
    "degree=1                      #choice of the degree of the polynomial expansion\n",
    "max_iters=50                  #max number of iterations for GD and SGD\n",
    "gamma=0.007                    #step size for GD and SGD\n",
    "lambda_=0.001                  #factor of the regularization for the ridge and logistic regression\n",
    "OUTPUT_PATH='submission.csv'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.672496"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning and adapting the data---------------------------------------------------------------------------------\n",
    "\n",
    "x_0,x_1,x_23=adapt_x(tX,degree)\n",
    "if choice=='least squares':\n",
    "    y_0,y_1,y_23=adapt_y_least_squares(y,tX)\n",
    "elif choice=='logistic regression':\n",
    "    y_0,y_1,y_23=adapt_y_logistic(y,tX)\n",
    "else:\n",
    "    raise SyntaxWarning\n",
    "\n",
    "#Computing the weights and loss on the training set-------------------------------------------------------------\n",
    "\n",
    "#Gradient descent\n",
    "#w_0, loss_w0 = least_squares_SGD(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = least_squares_SGD(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = least_squares_SGD(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Stochastic gradient descent\n",
    "#w_0, loss_w0 = least_squares_SGD(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = least_squares_SGD(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = least_squares_SGD(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Least squares with normal equations\n",
    "#w_0, loss_w0 = least_squares(y_0, x_0)\n",
    "#w_1, loss_w1 = least_squares(y_1, x_1)\n",
    "#w_23, loss_w2 = least_squares(y_23, x_23)\n",
    "\n",
    "#Ridge regression\n",
    "#w_0, loss_w0 = ridge_regression(y_0, x_0, lambda_)\n",
    "#w_1, loss_w1 = ridge_regression(y_1, x_1, lambda_)\n",
    "#w_23, loss_w2 = ridge_regression(y_23, x_23, lambda_)\n",
    "\n",
    "#Logistic regression\n",
    "#w_0, loss_w0 = logistic_regression(y_0, x_0, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "#w_1, loss_w1 = logistic_regression(y_1, x_1, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "#w_23, loss_w2 = logistic_regression(y_23, x_23, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Regularized logistic regression\n",
    "w_0, loss_w0 = reg_logistic_regression(y_0, x_0, lambda_, np.zeros(x_0.shape[1]), max_iters,gamma)\n",
    "w_1, loss_w1 = reg_logistic_regression(y_1, x_1, lambda_, np.zeros(x_1.shape[1]), max_iters,gamma)\n",
    "w_23, loss_w2 = reg_logistic_regression(y_23, x_23, lambda_, np.zeros(x_23.shape[1]), max_iters,gamma)\n",
    "\n",
    "#Predict on the train set----------------------------------------------------------------------------------------\n",
    "\n",
    "y_pred_tr = label(w_0,w_1,w_23,x_0,x_1,x_23,tX,choice)\n",
    "compute_accuracy(y, y_pred_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create the submission file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning and adapting the data----------------------------------------------------------------------------------\n",
    "x_0_te,x_1_te,x_23_te=adapt_x(tX_test,degree)\n",
    "\n",
    "#Predict on the test set-----------------------------------------------------------------------------------------\n",
    "y_pred_te=label_regression(w_0,w_1,w_23,x_0_te,x_1_te,x_23_te,tX_test,choice)\n",
    "create_csv_submission(ids_test, y_pred_te, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
